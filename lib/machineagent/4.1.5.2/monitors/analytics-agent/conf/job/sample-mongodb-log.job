#
# Refer to the end of this file to have a look at a sample format of the
# log file that this job is meant to process.
#

# The version of this job configuration file. This should not be changed by the user.
version: 1

# Optional property. Defaults to "false"
#
enabled: false
startAtEnd: false

# Mandatory property.
#
# On Windows, path should be provided as if on Unix environments.
#   Ex: demo/logs
#   Ex: C:/app/logs
#
file:
    path: /var/log/mongodb
    nameGlob: mongodb.log

# Optional property (Except "sourceType").
#
# These fields are in addition to the data that is already present in the
# files being tailed. Each record read from the file will be enriched with
# these fields.
#
fields:
   sourceType: mongodb-log
   nodeName: TravelNode
   tierName: AppTier
   appName: MongoDB

# Optional property.
#
# Grok is a way to define and use complex, nested regular expressions in an
# easy to read and use format.
#
# A Grok pattern ultimately resolves and compiles into a regular expression.
# The advantage of using Grok is its ability to compose complex patterns from
# simpler pattern definitions, like a "formal grammar".
#
# See https://grokdebug.herokuapp.com/patterns for examples.
#
# The application comes pre-loaded with some well known Grok patterns in
# the form of ".grok" files. They are available under the "conf/grok" directory.
# Custom Grok files can be added to this directory and they will be
# available for use here when the application is restarted.
#
# The Grok patterns here are meant to match a part of the log "message" string.
# If multiple Grok patterns are provided, each one will be applied to the
# "message" string individually.
#
# A Grok pattern is really a regular expression with the option of referencing
# other known Grok patterns by name. Like this "%{JAVACLASS:myClassName}".
# This means that we are looking for a sub-string that looks like a Java Class
# name. Once the pattern is found, the matching sub-string will be extracted
# and stored separately as a first class field, with "myClassName" as the key.
#
# By default, these patterns do not match multiline strings. To look for
# the pattern sub-string across a multiline string, please refer to:
# http://docs.oracle.com/javase/7/docs/api/java/util/regex/Pattern.html#DOTALL
#
grok:
   patterns:
     - "%{TIMESTAMP_ISO8601:eventTimestamp} \\[%{WORD:component}\\] %{GREEDYDATA:message}"

# Optional property.
#
# If records have a timestamp that should be used as "the" eventTimestamp then
# the format can be provided here to ensure that the string gets parsed and
# transformed correctly to UTC time zone.
#
# An attempt will be made to extract the timestamp automatically, failing which
# one will be added at the time the record is read from the file.
#
# UTC time zone is used throughout the system to ensure consistency of
# timestamps across sources from different time zones. This means that all
# timestamps should be converted to UTC time zone.
#
# If the format ends with a "z" or "Z" then the time zone offset is used to
# convert to UTC time. No time zone means local time zone.
#
# A reference list of available patterns can be found here:
# http://www.joda.org/joda-time/key_format.html
#
eventTimestamp:
   pattern: "yyyy-MM-dd'T'HH:mm:ss.SSSZ"


# ####################################
# ###   Start sample file format   ###
# ####################################
#
# 2015-01-14T15:10:29.385+0530 [PeriodicTaskRunner] task: DBConnectionPool-cleaner took: 0ms
# 2015-01-14T15:10:29.411+0530 [TTLMonitor] TTLMonitor thread awake
# 2015-01-14T15:10:29.412+0530 [TTLMonitor] Running query: query: { expireAfterSeconds: { $exists: true } } sort: {} projection: {} skip: 0 limit: 0
# 2015-01-14T15:10:29.412+0530 [TTLMonitor] query admin.system.indexes query: { expireAfterSeconds: { $exists: true } } planSummary: EOF ntoreturn:0 ntoskip:0 nscanned:0 nscannedObjects:0 keyUpdates:0 numYields:0 locks(micros) r:661 nreturned:0 reslen:20 0ms
# 2015-01-14T15:10:29.412+0530 [TTLMonitor] Running query: query: { expireAfterSeconds: { $exists: true } } sort: {} projection: {} skip: 0 limit: 0
# 2015-01-14T15:10:29.412+0530 [TTLMonitor] Only one plan is available; it will be run but will not be cached. query: { expireAfterSeconds: { $exists: true } } sort: {} projection: {} skip: 0 limit: 0, planSummary: COLLSCAN
# 2015-01-14T15:10:29.412+0530 [TTLMonitor] query local.system.indexes query: { expireAfterSeconds: { $exists: true } } planSummary: COLLSCAN ntoreturn:0 ntoskip:0 nscanned:1 nscannedObjects:1 keyUpdates:0 numYields:0 locks(micros) r:200 nreturned:0 reslen:20 0ms
# 2015-01-14T15:10:29.413+0530 [TTLMonitor] Running query: query: { expireAfterSeconds: { $exists: true } } sort: {} projection: {} skip: 0 limit: 0
# 2015-01-14T15:10:29.413+0530 [TTLMonitor] Only one plan is available; it will be run but will not be cached. query: { expireAfterSeconds: { $exists: true } } sort: {} projection: {} skip: 0 limit: 0, planSummary: COLLSCAN
# 2015-01-14T15:10:29.413+0530 [TTLMonitor] query mydb.system.indexes query: { expireAfterSeconds: { $exists: true } } planSummary: COLLSCAN ntoreturn:0 ntoskip:0 nscanned:1 nscannedObjects:1 keyUpdates:0 numYields:0 locks(micros) r:228 nreturned:0 reslen:20 0ms
# 2015-01-14T15:10:29.451+0530 [clientcursormon] mem (MB) res:39 virt:668
# 2015-01-14T15:10:29.451+0530 [clientcursormon]  mapped (incl journal view):480
#
# ##################################
# ###   End sample file format   ###
# ##################################
